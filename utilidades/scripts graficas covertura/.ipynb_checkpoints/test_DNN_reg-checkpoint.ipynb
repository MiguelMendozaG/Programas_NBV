{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from scipy.spatial import distance\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_file = np.loadtxt('/home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/6d pose/hinterstoisser/nubes/dataset/test_DNN/octree_pruned5.txt')\n",
    "##octree configuration parameters \n",
    "min_octrees_file = -0.106455  #object capsule param from partialModelCofig file\n",
    "max_octrees_file = -min_octrees_file\n",
    "min_cubo = 0\n",
    "max_cubo = 32\n",
    "\n",
    "m = (max_cubo - min_cubo) / (max_octrees_file - min_octrees_file)\n",
    "output_cube_size = 32*32*32\n",
    "\n",
    "b = cloud_file[:,3].reshape(32,32,32)\n",
    "print (b.shape)\n",
    "x_new = []\n",
    "y_new = []\n",
    "z_new = []\n",
    "val = []\n",
    "plt.imshow(b[:][:][10])\n",
    "plt.show()\n",
    "#mpld3.display()\n",
    "\n",
    "for i in range(32):\n",
    "    for j in range(32):\n",
    "        for k in range(32):\n",
    "            if b[i][j][k] >= 0.5 and b[i][j][k] < 0.6:\n",
    "                x_new.append(i)\n",
    "                y_new.append(j)\n",
    "                z_new.append(k)\n",
    "                val.append(0)\n",
    "            elif b[i][j][k] >= 0.6:\n",
    "                x_new.append(i)\n",
    "                y_new.append(j)\n",
    "                z_new.append(k)\n",
    "                val.append(255)\n",
    "                \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x_new,y_new,z_new, c = val)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxnet(x, n_classes = 3 ):\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    #limpiar graficas anteriores\n",
    "    #reset_graph()\n",
    "    \n",
    "    #Imagenes \n",
    "    img = tf.reshape(x, shape=[-1, 32,32,32,1])\n",
    "    #tf.summary.image(\"Image\", img)\n",
    "    # Declarando las variables \n",
    "    weights = {'W_conv1':tf.Variable(tf.truncated_normal([5,5,5,1,32], mean = mu, stddev = sigma)),\n",
    "               'W_conv2':tf.Variable(tf.truncated_normal([3,3,3,32,32], mean = mu, stddev = sigma)),\n",
    "               'W_conv3':tf.Variable(tf.truncated_normal([3,3,3,12,8], mean = mu, stddev = sigma)),\n",
    "               'W_fc1':tf.Variable(tf.truncated_normal([8*8*8*32,128], mean = mu, stddev = sigma)),\n",
    "               'W_fc2':tf.Variable(tf.truncated_normal([1500, 500], mean = mu, stddev = sigma)),\n",
    "               'W_fc3':tf.Variable(tf.truncated_normal([500, 100], mean = mu, stddev = sigma)),\n",
    "               'W_fc4':tf.Variable(tf.truncated_normal([100,50], mean= mu, stddev= sigma)),\n",
    "               'out':tf.Variable(tf.truncated_normal([128, n_classes], mean = mu, stddev = sigma))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "              'b_conv2':tf.Variable(tf.random_normal([32])),\n",
    "              'b_conv3':tf.Variable(tf.random_normal([8])),\n",
    "              'b_fc1':tf.Variable(tf.random_normal([128])),\n",
    "              'b_fc2':tf.Variable(tf.random_normal([500])),\n",
    "              'b_fc3':tf.Variable(tf.random_normal([100])),\n",
    "              'b_fc4':tf.Variable(tf.random_normal([50])),\n",
    "              'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "   \n",
    "    \n",
    "    \n",
    "    # Declarando la arquitectura\n",
    "    \n",
    "    #Input: 200x200x3     Output: 50x50x3\n",
    "    l1 = tf.nn.conv3d(img, weights['W_conv1'], strides=[1,2,2,2,1], padding='SAME')\n",
    "    l1 = tf.add(l1, biases['b_conv1'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    print(\"l1: \",l1.shape)\n",
    "    #l1 = tf.nn.dropout(l1, keep_rate)\n",
    "    #l1 = tf.nn.max_pool3d(l1, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='VALID')\n",
    "    \n",
    "    #Input: 50x50x3     Output: 50x50x6\n",
    "    l2 = tf.nn.conv3d(l1, weights['W_conv2'], strides=[1,1,1,1,1], padding='SAME')\n",
    "    l2 = tf.add(l2, biases['b_conv2'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    #l2 = tf.nn.dropout(l2, keep_rate)\n",
    "    #print(l2)\n",
    "    \n",
    "    #Input: 50x50x6     Output: 25x25x6\n",
    "    l2 = tf.nn.max_pool3d(l2, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='VALID')\n",
    "    print(\"l2: \",l2.shape)\n",
    "    \n",
    "    #l3 = tf.nn.conv3d(l2, weights['W_conv3'], strides=[1,1,1,1,1], padding='SAME')\n",
    "    #l3= tf.add(l3, biases['b_conv3'])\n",
    "    #l3 = tf.nn.relu(l3)\n",
    "    #l2 = tf.nn.dropout(l2, keep_rate2)\n",
    "    #print(l2)\n",
    "    \n",
    "    #Input: 50x50x6     Output: 25x25x6\n",
    "    #l3 = tf.nn.max_pool3d(l3, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='VALID')\n",
    "    #print(l3.shape)\n",
    "    \n",
    "    \n",
    "    #Input: 6x6x8     Output: 128\n",
    "    fc1 = tf.reshape(l2, [-1, 8*8*8*32])\n",
    "    fc1 = tf.nn.relu(tf.matmul(fc1, weights['W_fc1'])+biases['b_fc1'])\n",
    "    fc1 = tf.nn.dropout(fc1, keep_rate)\n",
    "                          \n",
    "    #Input: 128     Output: 64\n",
    "    #fc2 = tf.nn.relu(tf.matmul(fc1, weights['W_fc2'])+biases['b_fc2'])\n",
    "    #fc2 = tf.nn.dropout(fc2, keep_rate)\n",
    "    \n",
    "    #fc3 = tf.nn.relu(tf.matmul(fc2, weights['W_fc3'])+biases['b_fc3'])\n",
    "    #fc3 = tf.nn.dropout(fc3, keep_rate)\n",
    "    \n",
    "    #fc4 = tf.nn.relu(tf.matmul(fc3, weights['W_fc4'])+biases['b_fc4'])\n",
    "    #fc4 = tf.nn.dropout(fc4, keep_rate)\n",
    "\n",
    "    output_ = tf.matmul(fc1, weights['out'])+biases['out']\n",
    "\n",
    "    # Declarando la funcion de costo y entrenamiento\n",
    "    #cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y) )\n",
    "    #optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    #almacenar costo\n",
    "    #tf.summary.scalar(\"costo\", cost)\n",
    "    #generar logs\n",
    "    #summaries = tf.summary.merge_all()\n",
    "    \n",
    "    return output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12849872  0.11118321  0.36211376] 105\n"
     ]
    }
   ],
   "source": [
    "points = [-0.128, 0.111, 0.36]\n",
    "best_distance = []\n",
    "min_distance = 1000\n",
    "pos_number = 0\n",
    "pose_dir = sorted(glob.glob('/home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/6d pose/hinterstoisser/nubes/modelo7/position/pose/*.dat'))\n",
    "for file in pose_dir:\n",
    "    pose = np.genfromtxt(file)\n",
    "    number = re.search('_origin_(.+?).dat', file)\n",
    "    distance_ = distance.euclidean(pose,points)\n",
    "    if (distance_ < min_distance ):\n",
    "        min_distance = distance_\n",
    "        best_distance = pose\n",
    "        pos_number = int(number.group(1))\n",
    "        \n",
    "print(best_distance, pos_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
