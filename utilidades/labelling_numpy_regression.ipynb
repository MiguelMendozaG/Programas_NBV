{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.spatial import distance\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loads the points of a sphere to make assign groups in the classification process\n",
    "reference_points = np.genfromtxt('points_in_sphere.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_values(dir_file):\n",
    "    with open(dir_file, 'r') as config_folder:\n",
    "        for line in itertools.islice(config_folder, 12):pass\n",
    "        val_octree = re.findall(r'[+-]?[0-9.]+', line)\n",
    "        #print(float(val_octree[1]))\n",
    "    return float(val_octree[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing folder:  1  : 0  , 1035  , 1080  , 1125  , 1170  , 1215  , 1260  , 1305  , 170  , 215  , 260  , 305  , 350  , 40  , 445  , 490  , 530  , 575  , 620  , 665  , 710  , 755  , 800  , 85  , 895  , 940  , 985  , \n",
      " Processing folder:  2  : 0  , 1035  , 1080  , 1125  , 1170  , 1215  , 1260  , 1305  , 170  , 215  , 260  , 305  , 350  , 40  , 445  , 490  , 530  , 575  , 620  , 665  , 710  , 755  , 800  , 85  , 895  , 940  , 985  , \n",
      " Processing folder:  3  : 0  , 1035  , 1080  , 1125  , 1170  , 1215  , 1260  , 1305  , 170  , 215  , 260  , 305  , "
     ]
    }
   ],
   "source": [
    "dataset_dirs = [1,2,3,4,5,6,7,8,9,10,12,14]\n",
    "volumes = []\n",
    "clase = []\n",
    "pose = []\n",
    "orn = []\n",
    "#This programm labels the positions for every pose in the octree files\n",
    "for _, fig in enumerate(dataset_dirs):\n",
    "    if (fig > 6):\n",
    "        folder = sorted(glob.glob('/home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/6d pose/hinterstoisser/nubes/modelo' + str(int(fig)) + '/nbv/*'))\n",
    "    else:\n",
    "        folder = sorted(glob.glob('/media/miguelmg/EC6A24366A240046/dataset/modelo' + str(int(fig)) + '/nbv/*'))\n",
    "    numpy_file = \"/home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/6d pose/hinterstoisser/nubes/dataset/\"\n",
    "    print('\\n Processing folder: ', fig, ' :',end = ' ')\n",
    "\n",
    "    ##octree configuration parameters \n",
    "    min_octrees_file = config_values('/home/miguelmg/repositorios/vpl/data_example/FreeFlyer/config/partialModelConfig_model' + str(int(fig)) + '.ini')\n",
    "    max_octrees_file = -min_octrees_file\n",
    "    min_cubo = 0\n",
    "    max_cubo = 32\n",
    "\n",
    "    m = (max_cubo - min_cubo) / (max_octrees_file - min_octrees_file)\n",
    "    output_cube_size = 32*32*32\n",
    "\n",
    "    ## start the iterations over all the folders contained in the input folder\n",
    "    pos_indice = 0\n",
    "    folder_indice = 0\n",
    "    dataset = []\n",
    "    i_modulo = 0\n",
    "    \n",
    "    for folders in folder:\n",
    "        number = re.search('modelo' + str(int(fig)) + '/nbv/(.+)', folders)\n",
    "        #print(number.group(1))\n",
    "        #print (folders)\n",
    "        sub_folder = sorted(glob.glob(folders + '/octo_acum/*'))\n",
    "        num_files =\tint(len(sub_folder)/3) \n",
    "        ## all the octrees files are examined\n",
    "        for file_ in range(num_files):\n",
    "            file_ = file_ + 1\n",
    "\n",
    "            ### processing steps for the octree files\n",
    "            octree_file = np.loadtxt(folders + '/octo_acum/octomap_acum_' + str(file_) + '.txt', dtype = float) ## the current octree file is loaded in octree_file\n",
    "            #print(folders + '/octo_acum/octomap_acum_' + str(file_) + '.txt')\n",
    "            x = octree_file[:,0]\n",
    "            y = octree_file[:,1]\n",
    "            z = octree_file[:,2]\n",
    "            v = octree_file[:,3]\n",
    "            output_cube = np.zeros((32,32,32))\n",
    "            ##### the cube of the octree of size 32x32x32 is obtained\n",
    "            for i in range(output_cube_size):\n",
    "                x_cube = int((x[i]*m*2+32)/2)\n",
    "                y_cube = int((y[i]*m*2+32)/2)\n",
    "                z_cube = int((z[i]*m*2+32)/2)\n",
    "                output_cube[x_cube][y_cube][z_cube] = v[i]\n",
    "            ##### flatten representation of the cube is obtained\n",
    "            flatten_cube = output_cube.reshape(32*32*32)\n",
    "            ##### the first term of the tuple is saved in tuple_first\n",
    "            #tuple_first = output_cube\n",
    "\n",
    "            ### processing steps for the position, one hot enconding is obtained\n",
    "            num_point = 0\n",
    "            min_distance = 1\n",
    "            pos_file = np.genfromtxt(folders + \"/poses/pose_orientation/pose_orn\" + str(file_) + \".dat\")\n",
    "            pos_coord = pos_file[0]\n",
    "            orn_coord = pos_file[1]\n",
    "            #print(orn_coord)\n",
    "            ###################################################\n",
    "            ############# CLASE ###############################\n",
    "            ###################################################\n",
    "            ###### the current pose is compared with all the points in the sphere\n",
    "            for points in reference_points:\n",
    "                distance_ = distance.euclidean(points, pos_coord)\n",
    "                if (distance_ < min_distance):\n",
    "                    min_distance = distance_\n",
    "                    pos_indice = num_point\n",
    "                num_point = num_point + 1\n",
    "            ######### one hot encoding is created\n",
    "            clase.append([pos_indice])\n",
    "            ####################################################\n",
    "            \n",
    "            \n",
    "            ####################################################\n",
    "            ################ Regression ########################\n",
    "            ####################################################\n",
    "            pose.append(pos_coord)\n",
    "            orn.append(orn_coord)\n",
    "            \n",
    "            ####################################################\n",
    "            ################ Volumes ###########################\n",
    "            ####################################################\n",
    "            volumes.append(flatten_cube)\n",
    "        if (i_modulo % 50 ==0):\n",
    "            print(number.group(1) , ' ,', end = ' ' )\n",
    "        i_modulo += 5\n",
    "        \n",
    "\n",
    "pose = np.array(pose)\n",
    "orn = np.array(orn)\n",
    "clase = np.array(clase)\n",
    "volumes = np.array(volumes)\n",
    "        \n",
    "#np.save(numpy_file + 'dataset_volmues', volumes)\n",
    "#np.save(numpy_file + 'dataset_lbl_pose', pose)\n",
    "#np.save(numpy_file + 'dataset_lbl_orn', orn)\n",
    "#np.save(numpy_file + 'dataset_lbl_clase', clase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = np.array(pose)\n",
    "clase = np.array(clase)\n",
    "volumes = np.array(volumes)\n",
    "print((volumes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas para cargar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_load_path = \"/home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/11_ref_100_vol.npy\"\n",
    "dataset_load_lbl_path = \"/home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/11_ref_100_lbl.npy\"\n",
    "dataset = np.load(dataset_load_path)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ = np.load(dataset_load_lbl_path)\n",
    "print((labels_.shape))\n",
    "labels_ = np.array(labels_)\n",
    "print(labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = np.zeros((len(labels_),14))\n",
    "one_hot[np.arange(len(labels_)),labels_]=1\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
