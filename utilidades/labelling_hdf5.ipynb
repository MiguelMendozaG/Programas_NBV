{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_data = True  # shuffle the addresses before saving\n",
    "hdf5_path = '/home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/6d pose/hinterstoisser/nubes/dataset/dataset_completo.hdf5'  # address to where you want to save the hdf5 file\n",
    "dataset_train_path = '/home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/6d pose/hinterstoisser/nubes/dataset/completo/*.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "addrs = glob.glob(dataset_train_path)\n",
    "labels = []\n",
    "#extraer el primer numero del nombre del archivo, para guardar en un arreglo\n",
    "for file in addrs:\n",
    "    m = re.search('completo/(.+?)_', file)\n",
    "    #print (m.group(1))\n",
    "    labels.append(int(m.group(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 /home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/6d pose/hinterstoisser/nubes/dataset/completo/10_220_12_2.txt\n"
     ]
    }
   ],
   "source": [
    "labl = 60\n",
    "print (labels[labl], addrs[labl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c)\n",
    "    addrs, labels = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 /home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/6d pose/hinterstoisser/nubes/dataset/completo/3_780_1_6.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labl = 60\n",
    "print (labels[labl], addrs[labl])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_addrs = addrs[0:int(0.8*len(addrs))]\n",
    "train_labels = labels[0:int(0.8*len(labels))]\n",
    "\n",
    "test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "test_labels = labels[int(0.8*len(labels)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguelmg/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_order = 'tf'  # 'th' for Theano, 'tf' for Tensorflow\n",
    "# check the order of data and chose proper data shape to save images\n",
    "if data_order == 'th': # it is not used\n",
    "    train_shape = (len(train_addrs), 3, 224, 224)\n",
    "elif data_order == 'tf':\n",
    "    train_shape = (len(train_addrs), 32, 32, 32)\n",
    "    test_shape = (len(test_addrs), 32, 32, 32)\n",
    "# open a hdf5 file and create earrays\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "\n",
    "#hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "\n",
    "hdf5_file.create_dataset(\"train_img\", train_shape, np.float32)\n",
    "hdf5_file.create_dataset(\"train_labels\", (len(train_addrs),), np.int8)\n",
    "hdf5_file[\"train_labels\"][...] = train_labels\n",
    "\n",
    "hdf5_file.create_dataset(\"test_img\", test_shape, np.float32)\n",
    "hdf5_file.create_dataset(\"test_labels\", (len(test_addrs),), np.int8)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 100/10764\n",
      "Train data: 200/10764\n",
      "Train data: 300/10764\n",
      "Train data: 400/10764\n",
      "Train data: 500/10764\n",
      "Train data: 600/10764\n",
      "Train data: 700/10764\n",
      "Train data: 800/10764\n",
      "Train data: 900/10764\n",
      "Train data: 1000/10764\n",
      "Train data: 1100/10764\n",
      "Train data: 1200/10764\n",
      "Train data: 1300/10764\n",
      "Train data: 1400/10764\n",
      "Train data: 1500/10764\n",
      "Train data: 1600/10764\n",
      "Train data: 1700/10764\n",
      "Train data: 1800/10764\n",
      "Train data: 1900/10764\n",
      "Train data: 2000/10764\n",
      "Train data: 2100/10764\n",
      "Train data: 2200/10764\n",
      "Train data: 2300/10764\n",
      "Train data: 2400/10764\n",
      "Train data: 2500/10764\n",
      "Train data: 2600/10764\n",
      "Train data: 2700/10764\n",
      "Train data: 2800/10764\n",
      "Train data: 2900/10764\n",
      "Train data: 3000/10764\n",
      "Train data: 3100/10764\n",
      "Train data: 3200/10764\n",
      "Train data: 3300/10764\n",
      "Train data: 3400/10764\n",
      "Train data: 3500/10764\n",
      "Train data: 3600/10764\n",
      "Train data: 3700/10764\n",
      "Train data: 3800/10764\n",
      "Train data: 3900/10764\n",
      "Train data: 4000/10764\n",
      "Train data: 4100/10764\n",
      "Train data: 4200/10764\n",
      "Train data: 4300/10764\n",
      "Train data: 4400/10764\n",
      "Train data: 4500/10764\n",
      "Train data: 4600/10764\n",
      "Train data: 4700/10764\n",
      "Train data: 4800/10764\n",
      "Train data: 4900/10764\n",
      "Train data: 5000/10764\n",
      "Train data: 5100/10764\n",
      "Train data: 5200/10764\n",
      "Train data: 5300/10764\n",
      "Train data: 5400/10764\n",
      "Train data: 5500/10764\n",
      "Train data: 5600/10764\n",
      "Train data: 5700/10764\n",
      "Train data: 5800/10764\n",
      "Train data: 5900/10764\n",
      "Train data: 6000/10764\n",
      "Train data: 6100/10764\n",
      "Train data: 6200/10764\n",
      "Train data: 6300/10764\n",
      "Train data: 6400/10764\n",
      "Train data: 6500/10764\n",
      "Train data: 6600/10764\n",
      "Train data: 6700/10764\n",
      "Train data: 6800/10764\n",
      "Train data: 6900/10764\n",
      "Train data: 7000/10764\n",
      "Train data: 7100/10764\n",
      "Train data: 7200/10764\n",
      "Train data: 7300/10764\n",
      "Train data: 7400/10764\n",
      "Train data: 7500/10764\n",
      "Train data: 7600/10764\n",
      "Train data: 7700/10764\n",
      "Train data: 7800/10764\n",
      "Train data: 7900/10764\n",
      "Train data: 8000/10764\n",
      "Train data: 8100/10764\n",
      "Train data: 8200/10764\n",
      "Train data: 8300/10764\n",
      "Train data: 8400/10764\n",
      "Train data: 8500/10764\n",
      "Train data: 8600/10764\n",
      "Train data: 8700/10764\n",
      "Train data: 8800/10764\n",
      "Train data: 8900/10764\n",
      "Train data: 9000/10764\n",
      "Train data: 9100/10764\n",
      "Train data: 9200/10764\n",
      "Train data: 9300/10764\n",
      "Train data: 9400/10764\n",
      "Train data: 9500/10764\n",
      "Train data: 9600/10764\n",
      "Train data: 9700/10764\n",
      "Train data: 9800/10764\n",
      "Train data: 9900/10764\n",
      "Train data: 10000/10764\n",
      "Train data: 10100/10764\n",
      "Train data: 10200/10764\n",
      "Train data: 10300/10764\n",
      "Train data: 10400/10764\n",
      "Train data: 10500/10764\n",
      "Train data: 10600/10764\n",
      "Train data: 10700/10764\n",
      "Test data: 100/2691\n",
      "Test data: 200/2691\n",
      "Test data: 300/2691\n",
      "Test data: 400/2691\n",
      "Test data: 500/2691\n",
      "Test data: 600/2691\n",
      "Test data: 700/2691\n",
      "Test data: 800/2691\n",
      "Test data: 900/2691\n",
      "Test data: 1000/2691\n",
      "Test data: 1100/2691\n",
      "Test data: 1200/2691\n",
      "Test data: 1300/2691\n",
      "Test data: 1400/2691\n",
      "Test data: 1500/2691\n",
      "Test data: 1600/2691\n",
      "Test data: 1700/2691\n",
      "Test data: 1800/2691\n",
      "Test data: 1900/2691\n",
      "Test data: 2000/2691\n",
      "Test data: 2100/2691\n",
      "Test data: 2200/2691\n",
      "Test data: 2300/2691\n",
      "Test data: 2400/2691\n",
      "Test data: 2500/2691\n",
      "Test data: 2600/2691\n"
     ]
    }
   ],
   "source": [
    "# loop over train addresses\n",
    "for i in range(len(train_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 100 == 0 and i > 1:\n",
    "        print ('Train data: {}/{}'.format(i, len(train_addrs)))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = train_addrs[i]\n",
    "    img = np.loadtxt(addr, dtype = float)\n",
    "    img = img.reshape(32,32,32)\n",
    "\n",
    "    # save the image\n",
    "    hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "\n",
    "# loop over test addresses\n",
    "for i in range(len(test_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 100 == 0 and i > 1:\n",
    "        print ('Test data: {}/{}'.format(i, len(test_addrs)))\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = test_addrs[i]\n",
    "    img = np.loadtxt(addr, dtype = float)\n",
    "    img = img.reshape(32,32,32)\n",
    "\n",
    "    # save the image \n",
    "    hdf5_file[\"test_img\"][i, ...] = img[None]\n",
    "    \n",
    "    \n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "hdf5_path = '/home/miguelmg/Documents/CIDETEC/semestre 2/vision 3d/proyecto/6d pose/hinterstoisser/nubes/dataset/dataset_completo.hdf5'  # address to where you want to save the hdf5 file\n",
    "#subtract_mean = False\n",
    "# open the hdf5 file\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "# subtract the training mean\n",
    "#if subtract_mean:\n",
    " #   mm = hdf5_file[\"train_mean\"][0, ...]\n",
    " #   mm = mm[np.newaxis, ...]\n",
    "# Total number of samples\n",
    "data_num = hdf5_file[\"train_img\"][0]\n",
    "lbl = hdf5_file[\"train_labels\"][0]\n",
    "print (data_num.shape)\n",
    "print (lbl)\n",
    "#plt.imshow(data_num[:][:][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
